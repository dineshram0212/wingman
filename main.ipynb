{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wingman.core.wingman import Wingman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Wingman(model_name='llama-3.3-70b-versatile', apiKey='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.chat(\"I peed my pants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'event'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mtype.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Whoa, that's okay, accidents happen. Do you need any help or a funny joke to lighten the mood?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wingman.core.memory import Memory\n",
    "\n",
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Wingman(model_name='llama-3.3-70b-versatile', apiKey='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = \"yesterday was my birthday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.chat(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy belated birthday! I hope you had an amazing day and got to celebrate with loved ones. How did you spend your special day?'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtype = result.mtype.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'event'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"No birthday was day before today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3fd306b9-30df-4504-a06f-4b3b10c7ba15']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.save_memory(memory_type=mtype, docs=[f\"User: '{chat}'; Response: '{result.response}'\"])\n",
    "memory.save_memory(memory_type='test', docs=[f\"User: '{chat}'; Response: '{test}'\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 February 2025,  05:16 PM\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "\n",
    "print(x.strftime(\"%d %B %Y,  %I:%M %p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = \"When is my birthday yesterdat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short\n"
     ]
    }
   ],
   "source": [
    "print(client.classify_memory(chat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrvd_memory = memory.load_memory(chat, memory_type='test', min_score=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = client.chat(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(response=\"I'm not aware of your birthday details. Could you please provide more context or information about your birthday?\", mtype=<MemoryType.short: 'short'>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wingman.core.wingman import Wingman\n",
    "\n",
    "client = Wingman(model_name='llama-3.3-70b-versatile', apiKey='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Type:  event\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(response='Yes, I remember you told me yesterday was your birthday. Happy belated birthday again!', mtype='long')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat(\"Do you remember my birthday?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Type:  event\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(response='Your birthday was not on yesterday, but since we were talking about your birthday earlier, I will remember that your birthday is today, February 28, 2025.', mtype='long')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat(\"No my birthday was not on yesterday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "model = OllamaLLM(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage\n",
    "builder = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(START, \"model\")\n",
    "builder.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "query = \"No my name is Ram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello Ram! Nice to meet you too! Don't worry, it can be easy for names and conversations to get jumbled up. Let's start fresh - how are you doing today? Is everything okay?\n"
     ]
    }
   ],
   "source": [
    "input_messages = [HumanMessage(query)]\n",
    "output = graph.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wingman.core.memory import Memory\n",
    "\n",
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wingman.core.wingman import Wingman\n",
    "\n",
    "client = Wingman(model_name='qwen-2.5-32b', apiKey='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': 'Whats my name'}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Whats my name\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from langgraph.graph import MessagesState\n",
    "chat_message = \"Whats my name\"\n",
    "\n",
    "state = MessagesState(messages=chat_message)\n",
    "config= {\"configurable\": {\n",
    "            \"thread_id\": datetime.datetime.now().strftime('%d%m%Y'),\n",
    "        }}\n",
    "print(state)\n",
    "client.chat(state, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wingman.core.wingman import Wingman\n",
    "from langchain_core.messages import HumanMessage\n",
    "import datetime\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Initialize the client\n",
    "client = Wingman(model_name='qwen-2.5-32b', apiKey='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='I want it as object oriented program', additional_kwargs={}, response_metadata={})]}\n",
      "Loaded Messages:  [HumanMessage(content='Whats my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Dinesh.', additional_kwargs={}, response_metadata={}), HumanMessage(content='give me a python code to print if a year is leap year or not', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure, here\\'s a simple Python code snippet to determine if a given year is a leap year or not:\\n\\n```python\\ndef is_leap_year(year):\\n    if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\\n        return True\\n    else:\\n        return False\\n\\n# Example usage\\nyear = 2024\\nif is_leap_year(year):\\n    print(f\"{year} is a leap year.\")\\nelse:\\n    print(f\"{year} is not a leap year.\")\\n```\\nYou can replace the `year` variable with any year you want to check.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I want it as object oriented program', additional_kwargs={}, response_metadata={}, id='203a6d35-26a8-45a7-9b64-7c4653bae102')]\n",
      "\n",
      "Wingman's response:\n",
      "Sure, let's convert that into an object-oriented program. Here's how you can do it:\n",
      "\n",
      "```python\n",
      "class LeapYearChecker:\n",
      "    def __init__(self, year):\n",
      "        self.year = year\n",
      "\n",
      "    def is_leap_year(self):\n",
      "        if (self.year % 4 == 0 and self.year % 100 != 0) or (self.year % 400 == 0):\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "# Example usage\n",
      "year = 2024\n",
      "checker = LeapYearChecker(year)\n",
      "if checker.is_leap_year():\n",
      "    print(f\"{year} is a leap year.\")\n",
      "else:\n",
      "    print(f\"{year} is not a leap year.\")\n",
      "```\n",
      "You can modify the `year` variable to test different years.\n"
     ]
    }
   ],
   "source": [
    "# Create a proper message state\n",
    "chat_message = \"I want it as object oriented program\"\n",
    "state = MessagesState(messages=[HumanMessage(content=chat_message)])\n",
    "\n",
    "# Configure with thread_id\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": datetime.datetime.now().strftime('%d%m%Y'),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print the state\n",
    "print(state)\n",
    "\n",
    "# Call the chat method and print the response\n",
    "response = client.chat(state, config=config)\n",
    "print(\"\\nWingman's response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Write a python code to predict if leap year or not.', additional_kwargs={}, response_metadata={}, id='30f3592f-8d2a-48e3-a8b0-2ca801bbbf1d'), ResponseFormatter(response=\"Here's a simple Python function to determine if a year is a leap year or not:\\n\\ndef is_leap_year(year):\\n    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\\n\\n# Example usage:\\nyear = 2024\\nif is_leap_year(year):\\n    print(f'{year} is a leap year.')\\nelse:\\n    print(f'{year} is not a leap year.')\", mtype='none'), HumanMessage(content='Give it as object oriented program.', additional_kwargs={}, response_metadata={}, id='18c29e85-c9df-402b-8bc8-7e20a702522f'), ResponseFormatter(response=\"Here's the equivalent object-oriented Python program to determine if a year is a leap year or not:\\n\\nclass Year:\\n    def __init__(self, year):\\n        self.year = year\\n\\n    def is_leap_year(self):\\n        return self.year % 4 == 0 and (self.year % 100 != 0 or self.year % 400 == 0)\\n\\n# Example usage:\\nyear = Year(2024)\\nif year.is_leap_year():\\n    print(f'{year.year} is a leap year.')\\nelse:\\n    print(f'{year.year} is not a leap year.')\", mtype='none')])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_chat_history(datetime.datetime.now().strftime('%d%m%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'04032025': InMemoryChatMessageHistory(messages=[HumanMessage(content='Whats my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Dinesh.', additional_kwargs={}, response_metadata={}), HumanMessage(content='give me a python code to print if a year is leap year or not', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure, here\\'s a simple Python code snippet to determine if a given year is a leap year or not:\\n\\n```python\\ndef is_leap_year(year):\\n    if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\\n        return True\\n    else:\\n        return False\\n\\n# Example usage\\nyear = 2024\\nif is_leap_year(year):\\n    print(f\"{year} is a leap year.\")\\nelse:\\n    print(f\"{year} is not a leap year.\")\\n```\\nYou can replace the `year` variable with any year you want to check.', additional_kwargs={}, response_metadata={})])}\n"
     ]
    }
   ],
   "source": [
    "print(client.chats_by_thread_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wingman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
